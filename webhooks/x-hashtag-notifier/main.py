import requests
import time
import json
import os
import logging
from logging.handlers import RotatingFileHandler
from dotenv import load_dotenv
from datetime import datetime, timezone, timedelta

# ë¡œê·¸ ì„¤ì •
LOG_DIR = "logs"
LOG_FILE = os.path.join(LOG_DIR, "hashtag.log")
os.makedirs(LOG_DIR, exist_ok=True)

logger = logging.getLogger("HashtagMonitor")
logger.setLevel(logging.INFO)

handler = RotatingFileHandler(LOG_FILE, maxBytes=5 * 1024 * 1024, backupCount=5)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
BEARER_TOKEN = os.getenv("TWITTER_BEARER_TOKEN")  # íŠ¸ìœ„í„° API í† í°
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")  # ë””ìŠ¤ì½”ë“œ ì›¹í›… URL

# í•´ì‹œíƒœê·¸ ëª©ë¡ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (êµ¬ë¶„ì : ",")
HASHTAGS = [tag.strip() for tag in os.getenv("MONITOR_HASHTAGS", "#ë‹¨ê°„ì¥í„°,#ë‹¨ê°„ë¡ íŒŒì¥í„°,#ë‹¨ê°„ë¡ íŒŒ_ì¥í„°").split(",")]

SEEN_FILE = os.getenv("SEEN_FILE", "seen_tweets.json")  # ì´ë¯¸ ì•Œë¦¼ì„ ë³´ë‚¸ íŠ¸ìœ— ID ì €ì¥ íŒŒì¼
CHECK_INTERVAL = int(os.getenv("CHECK_INTERVAL", "60"))  # íŠ¸ìœ— ê²€ìƒ‰ ì£¼ê¸°(ì´ˆ)

HEADERS = {
    "Authorization": f"Bearer {BEARER_TOKEN}"
}

# íƒ€ì„ì¡´ ë° ì‹œì‘ ì‹œê°„ ì„¤ì •
KST = timezone(timedelta(hours=9))
start_time = datetime.now(KST)
logger.info(f"ğŸ•’ ë´‡ ì‹œì‘ ì‹œê°„ (Asia/Seoul ê¸°ì¤€): {start_time.strftime('%Y-%m-%d %H:%M:%S')}")

# ì¤‘ë³µ ê°ì§€
def load_seen_ids():
    # ì´ë¯¸ ì•Œë¦¼ì„ ë³´ë‚¸ íŠ¸ìœ— ID ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(SEEN_FILE):
        try:
            with open(SEEN_FILE, 'r') as f:
                return set(json.load(f))
        except json.JSONDecodeError:
            logger.warning("âš ï¸ seen_tweets.json íŒŒì‹± ì˜¤ë¥˜. ë¹ˆ ëª©ë¡ìœ¼ë¡œ ì´ˆê¸°í™”.")
    return set()

def save_seen_ids(ids):
    # íŠ¸ìœ— ID ëª©ë¡ ì €ì¥
    try:
        with open(SEEN_FILE, 'w') as f:
            json.dump(list(ids), f)
    except Exception as e:
        logger.error(f"âŒ íŠ¸ìœ— ID ì €ì¥ ì‹¤íŒ¨: {e}")

# ë””ìŠ¤ì½”ë“œ ì „ì†¡
def send_discord_alert(username, tweet_id, tag, created_at_kst):
    # ë””ìŠ¤ì½”ë“œ ì›¹í›… íŠ¸ìœ— ì•Œë¦¼ ì „ì†¡
    try:
        content = (
            f"ğŸ”” **í•´ì‹œíƒœê·¸ {tag} íŠ¸ìœ— ë°œê²¬!**\n"
            f"ì‘ì„±ì: @{username}\n"
            f"ì‘ì„± ì‹œê° (KST): {created_at_kst}\n\n"
            f"https://twitter.com/{username}/status/{tweet_id}"
        )

        payload = {"content": content}
        response = requests.post(DISCORD_WEBHOOK_URL, json=payload)

        if response.status_code != 204:
            logger.error(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì‹¤íŒ¨: {response.status_code} - {response.text}")

    except Exception as e:
        logger.error(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

def text_crop(text, limit=300):
    return text if len(text) <= limit else text[:limit] + "..."

# íŠ¸ìœ„í„° API ê²€ìƒ‰
def search_new_tweets(tag, seen_ids):
    # ì§€ì •í•œ í•´ì‹œíƒœê·¸ë¡œ ìƒˆ íŠ¸ìœ— ê²€ìƒ‰ ë° ì•Œë¦¼
    new_ids = set()
    url = "https://api.twitter.com/2/tweets/search/recent"
    params = {
        "query": f"{tag} lang:ko -is:retweet",  # í•œê¸€, ë¦¬íŠ¸ìœ— ì œì™¸
        "max_results": 10,
        "tweet.fields": "author_id,text,id,created_at",
        "expansions": "author_id",
        "user.fields": "username"
    }

    try:
        response = requests.get(url, headers=HEADERS, params=params)
        if response.status_code != 200:
            logger.error(f"âŒ Twitter API ìš”ì²­ ì‹¤íŒ¨ ({tag}): {response.status_code} - {response.text}")
            return new_ids

        data = response.json()

        if "data" not in data:
            logger.info(f"â„¹ï¸ '{tag}' ê´€ë ¨ ìƒˆ íŠ¸ìœ— ì—†ìŒ.")
            return new_ids

        users = {user["id"]: user["username"] for user in data["includes"]["users"]}

        for tweet in data["data"]:
            tweet_time_utc = datetime.fromisoformat(tweet["created_at"].replace("Z", "+00:00"))
            tweet_time_kst = tweet_time_utc.astimezone(KST)
            if tweet["id"] not in seen_ids and tweet_time_kst > start_time:
                username = users.get(tweet["author_id"], "unknown")
                logger.info(f"ğŸ“Œ ìƒˆ íŠ¸ìœ— ê°ì§€: @{username} - {tweet['id']} ({tweet_time_kst})")
                send_discord_alert(username, tweet["id"], tag, tweet_time_kst.strftime('%Y-%m-%d %H:%M:%S'))
                new_ids.add(tweet["id"])
            else:
                break

    except Exception as e:
        logger.error(f"âŒ '{tag}' íŠ¸ìœ— ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

    return new_ids

# ë©”ì¸ ë£¨í”„
if __name__ == "__main__":
    # ì£¼ê¸°ì ìœ¼ë¡œ í•´ì‹œíƒœê·¸ íŠ¸ìœ— ê²€ìƒ‰, ì•Œë¦¼ ì „ì†¡
    while True:
        logger.info("ğŸ” í•´ì‹œíƒœê·¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        try:
            seen_ids = load_seen_ids()  # ê¸°ì¡´ì— ë³¸ íŠ¸ìœ— ID ë¶ˆëŸ¬ì˜¤ê¸°
            all_new_ids = set()

            for tag in HASHTAGS:
                logger.info(f"  â–¶ {tag} ê²€ìƒ‰ ì¤‘...")
                new_ids = search_new_tweets(tag, seen_ids)
                all_new_ids.update(new_ids)

            if all_new_ids:
                seen_ids.update(all_new_ids)
                save_seen_ids(seen_ids)

        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ë£¨í”„ ì˜¤ë¥˜: {e}")

        time.sleep(CHECK_INTERVAL)  # ì§€ì •í•œ ì£¼ê¸°ë§Œí¼ ëŒ€ê¸° í›„ ë°˜ë³µ